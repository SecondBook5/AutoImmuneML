{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Crunch 1 - Exploratory Analysis for Spatial Transcriptomics Prediction\n",
    "\n",
    "## Purpose of This Notebook\n",
    "This notebook is intended to facilitate an exploratory analysis of the data provided for **Crunch 1** of the Autoimmune Disease Machine Learning Challenge. The purpose of this analysis is to:\n",
    "- Understand the structure and characteristics of the datasets.\n",
    "- Validate the integrity and alignment of the data.\n",
    "- Identify patterns and relationships between the input data (`X`: H&E images) and output data (`Y`: spatial transcriptomics).\n",
    "- Provide a foundation for preprocessing steps, feature engineering, and model development.\n",
    "\n",
    "Exploratory data analysis (EDA) involves systematically reviewing and visualizing data to uncover meaningful insights. It is a critical step in any data science workflow, particularly when working with complex datasets like those in this challenge.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Dataset Inspection**:\n",
    "   - The structure and contents of the datasets will be examined. This includes reviewing `HE_registered`, `HE_original`, `anucleus`, and `transcripts`.\n",
    "   - Potential issues, such as missing data or misaligned images, will be identified.\n",
    "\n",
    "2. **Visualization**:\n",
    "   - The spatial organization of nuclei and gene expression in tissue regions will be explored.\n",
    "   - H&E image data will be visualized alongside transcriptomics data to understand how these modalities relate to each other spatially.\n",
    "\n",
    "3. **Statistical Analysis**:\n",
    "   - Distributions of gene expression and image features will be summarized.\n",
    "   - Correlations and patterns between the input (`X`) and output (`Y`) datasets will be analyzed to guide the development of features for modeling.\n",
    "\n",
    "## Inputs and Outputs\n",
    "### **Inputs (`X`)**\n",
    "1. **HE_registered**: These are H&E pathology images that have been registered to the coordinate system used by the spatial transcriptomics data. Registration ensures that the images are aligned with the gene expression measurements and simplifies downstream analysis. This dataset is recommended as it avoids the need for additional alignment.\n",
    "2. **HE_original**: These are the unaligned H&E images in their native pixel coordinates. While alignment may need to be performed manually, these images could provide additional flexibility for advanced preprocessing tasks.\n",
    "\n",
    "### **Outputs (`Y`)**\n",
    "1. **anucleus**: This dataset contains aggregated gene expression profiles for 460 genes, with one profile for each nucleus. The gene expression data has been log1p-normalized, a transformation that makes the data more manageable for machine learning by compressing large values and emphasizing smaller ones.\n",
    "2. **transcripts**: This dataset provides raw spatial transcriptomics data, including the expression levels of individual genes and their spatial locations within the tissue. These data are linked to specific nuclei and are aggregated to produce `anucleus`.\n",
    "\n",
    "## Success Metrics\n",
    "The goal of this analysis is to ensure that the datasets are ready for use in developing a predictive model. The ultimate objective of the challenge is to predict gene expression in regions of tissue where this information is held out.\n",
    "\n",
    "- **End Goal**: The prediction of log1p-normalized gene expression for 460 genes in held-out regions of the tissue.\n",
    "- **Evaluation Metric**: The predictions will be assessed using the Mean Squared Error (MSE), which measures the average squared difference between the predicted and actual gene expression values.\n",
    "\n",
    "By the conclusion of this notebook, the datasets will have been thoroughly explored, and actionable insights will have been generated to inform preprocessing, feature engineering, and model development.\n"
   ],
   "id": "164702238a5a8fef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:13:03.656238Z",
     "start_time": "2025-01-01T03:13:02.423835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "e6e9fad70aa787bb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:13:08.002739Z",
     "start_time": "2025-01-01T03:13:03.744303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spatialdata_plot\n",
    "import spatialdata as sd\n",
    "import scanpy as sc"
   ],
   "id": "936561065eebe63d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secondbook5/micromamba/envs/autoimmune_ml/lib/python3.11/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:13:24.670126Z",
     "start_time": "2025-01-01T03:13:08.008544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.config_loader import ConfigLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# Step 1: Initialize the ConfigLoader with the relative path to config.yaml\n",
    "config_loader = ConfigLoader(\"../../config.yaml\")\n",
    "\n",
    "# Step 2: Retrieve the raw_dir for Crunch 1 from the configuration\n",
    "raw_dir = config_loader.get_crunch_path(\"crunch1\", \"raw_dir\")\n",
    "\n",
    "# Step 3: Construct the full path to the .zarr file\n",
    "zarr_file_path = Path(raw_dir) / \"UC1_NI.zarr\"\n",
    "\n",
    "# Step 4: Load the .zarr file using spatialdata\n",
    "sdata = sd.read_zarr(str(zarr_file_path))\n",
    "\n",
    "# Step 5: Output the spatial data\n",
    "print(sdata)"
   ],
   "id": "6f0411d4c06b6ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatialData object, with associated Zarr store: /mnt/d/AutoImmuneML/broad-1-autoimmune-crunch1/data/UC1_NI.zarr\n",
      "├── Images\n",
      "│     ├── 'HE_nuc_original': DataArray[cyx] (1, 21000, 22000)\n",
      "│     └── 'HE_original': DataArray[cyx] (3, 21000, 22000)\n",
      "└── Tables\n",
      "      ├── 'anucleus': AnnData (80037, 460)\n",
      "      └── 'cell_id-group': AnnData (93686, 0)\n",
      "with coordinate systems:\n",
      "    ▸ 'global', with elements:\n",
      "        HE_nuc_original (Images), HE_original (Images)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T03:13:32.749416Z",
     "start_time": "2025-01-01T03:13:32.681563Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"[INFO] Available image keys:\", sdata.images.keys())\n",
   "id": "64fd5f79e615dd63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Available image keys: KeysView({'HE_nuc_original': <xarray.DataArray 'image' (c: 1, y: 21000, x: 22000)> Size: 2GB\n",
      "dask.array<from-zarr, shape=(1, 21000, 22000), dtype=uint32, chunksize=(1, 5792, 5792), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * c        (c) int64 8B 0\n",
      "  * y        (y) float64 168kB 0.5 1.5 2.5 3.5 ... 2.1e+04 2.1e+04 2.1e+04\n",
      "  * x        (x) float64 176kB 0.5 1.5 2.5 3.5 ... 2.2e+04 2.2e+04 2.2e+04\n",
      "Attributes:\n",
      "    transform:  {'global': Identity }, 'HE_original': <xarray.DataArray 'image' (c: 3, y: 21000, x: 22000)> Size: 1GB\n",
      "dask.array<from-zarr, shape=(3, 21000, 22000), dtype=uint8, chunksize=(3, 6688, 6688), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * c        (c) int64 24B 0 1 2\n",
      "  * y        (y) float64 168kB 0.5 1.5 2.5 3.5 ... 2.1e+04 2.1e+04 2.1e+04\n",
      "  * x        (x) float64 176kB 0.5 1.5 2.5 3.5 ... 2.2e+04 2.2e+04 2.2e+04\n",
      "Attributes:\n",
      "    transform:  {'global': Identity }})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Input (X) Data: H&E Images\n",
    "\n",
    "This function takes a list of image keys and titles renders the images using SpatialData's visualization capabilities, and arranges them in a single row of subplots for side-by-side comparison.\n",
    "\n",
    "The visualization works by rasterizing the data stored in the SpatialData object, which involves converting high-resolution vector-based spatial information into raster images that can be displayed on the screen.\n",
    "This is essential for exploring large tissue images, ensuring that the details are clearly visible while keeping memory usage manageable.\n",
    "\n",
    "How It Works:\n",
    "- The function creates a grid of subplots, each corresponding to an image key.\n",
    "- For each image key, the SpatialData object's `.pl.render_images` method is used to rasterize and display the image. This ensures compatibility with large images.\n",
    "- Titles are added to the subplots for clarity.\n",
    "- `tight_layout()` is called to prevent overlapping of subplot elements.\n",
    "### 2.1 Visualizing H&E Image"
   ],
   "id": "79a16fb4863ef518"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-01T03:13:59.752508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize the H&E images\n",
    "def visualize_he_images(sdata, image_keys, titles, figsize=(20, 10)):\n",
    "    \"\"\"\n",
    "    Visualize H&E images using SpatialData.\n",
    "\n",
    "    Args:\n",
    "        sdata (SpatialData): The spatial data object containing the images.\n",
    "        image_keys (list): List of keys for the images to visualize (e.g., [\"HE_nuc_original\", \"HE_original\"]).\n",
    "        titles (list): List of titles corresponding to the images.\n",
    "        figsize (tuple): Figure size for the plots.\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if len(image_keys) != len(titles):\n",
    "        raise ValueError(\"Length of image_keys must match length of titles.\")\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, len(image_keys), figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, key, title in zip(axes, image_keys, titles):\n",
    "        # Render the image and show it in the subplot\n",
    "        sdata.pl.render_images(key).pl.show(ax=ax, title=title, coordinate_systems=\"global\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for the quickstarter images\n",
    "visualize_he_images(\n",
    "    sdata,\n",
    "    image_keys=[\"HE_nuc_original\", \"HE_original\"],\n",
    "    titles=[\"H&E Registered Image\", \"H&E Original Image\"]\n",
    ")\n"
   ],
   "id": "8807268a275685b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mINFO    \u001B[0m Rasterizing image for faster rendering.                                                                   \n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.1 Analyze Pixel Intensities",
   "id": "93bf3e47295eec52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_pixel_intensities(sdata, keys):\n",
    "    \"\"\"\n",
    "    Analyze pixel intensities and display their distribution for images.\n",
    "\n",
    "    Args:\n",
    "        sdata (SpatialData): The spatial data object.\n",
    "        keys (list): Keys of the images to analyze.\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        # Extract the image as a NumPy array\n",
    "        image = sdata.images[key].to_numpy()\n",
    "\n",
    "        # Calculate statistics\n",
    "        mean_intensity = image.mean()\n",
    "        median_intensity = np.median(image)\n",
    "        std_dev = image.std()\n",
    "        min_intensity = image.min()\n",
    "        max_intensity = image.max()\n",
    "        shape = image.shape\n",
    "\n",
    "        # Log statistics\n",
    "        print(f\"[INFO] Image '{key}':\")\n",
    "        print(f\"  - Shape: {shape}\")\n",
    "        print(f\"  - Mean Intensity: {mean_intensity:.2f}\")\n",
    "        print(f\"  - Median Intensity: {median_intensity:.2f}\")\n",
    "        print(f\"  - Standard Deviation: {std_dev:.2f}\")\n",
    "        print(f\"  - Min Intensity: {min_intensity}\")\n",
    "        print(f\"  - Max Intensity: {max_intensity}\")\n",
    "\n",
    "        # Plot histogram of pixel intensities\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(image.flatten(), bins=100, color=\"blue\", alpha=0.7, log=True)\n",
    "        plt.title(f\"Pixel Intensity Distribution: {key}\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(\"Pixel Intensity\")\n",
    "        plt.ylabel(\"Frequency (log scale)\")\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "analyze_pixel_intensities(\n",
    "    sdata,\n",
    "    keys=[\"HE_nuc_original\", \"HE_original\"]\n",
    ")\n"
   ],
   "id": "edf3f6461594bde3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Nuclei Overlay and Feature Analysis\n",
    "\n",
    "In this section, we focus on analyzing nuclei features and overlaying their centroids on H&E images. The following tasks are performed to gain insights into the distribution and characteristics of nuclei in the dataset.\n",
    "\n",
    "#### 2.2.1 Nuclei Overlay on H&E Images\n",
    "This step involves overlaying the centroids of nuclei on the corresponding H&E image. This visualization helps to understand the spatial distribution of nuclei within the tissue.\n",
    "\n",
    "**Code Explanation:**\n",
    "- Validate the existence of required image keys in the dataset.\n",
    "- Extract the original H&E image and nuclei mask using the specified keys.\n",
    "- Compute centroids of the nuclei using `regionprops` from `skimage`.\n",
    "- Plot the H&E image and overlay the nuclei centroids using scatter points.\n",
    "\n",
    "**Results:**\n",
    "- The overlay visualization confirms the spatial arrangement and density of nuclei across the tissue.\n",
    "- The output highlights how nuclei are distributed in relation to the tissue structure."
   ],
   "id": "70e0640312e69f86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "def plot_nuclei_overlay(sdata, image_key, nuclei_key=\"HE_nuc_original\", marker_color=\"yellow\", marker_size=15):\n",
    "    \"\"\"\n",
    "    Overlay nuclei centroids on the H&E image.\n",
    "\n",
    "    Args:\n",
    "        sdata (SpatialData): The spatial data object.\n",
    "        image_key (str): Key of the H&E image.\n",
    "        nuclei_key (str): Key of the nuclei image.\n",
    "        marker_color (str): Color of the markers for nuclei centroids.\n",
    "        marker_size (int): Size of the markers for nuclei centroids.\n",
    "    \"\"\"\n",
    "    # Validate input keys\n",
    "    if image_key not in sdata.images.keys():\n",
    "        raise KeyError(f\"Image key '{image_key}' not found in SpatialData images.\")\n",
    "    if nuclei_key not in sdata.images.keys():\n",
    "        raise KeyError(f\"Nuclei key '{nuclei_key}' not found in SpatialData images.\")\n",
    "\n",
    "    # Load images\n",
    "    image = sdata.images[image_key].to_numpy()\n",
    "    nuclei = sdata.images[nuclei_key].to_numpy()\n",
    "\n",
    "    # Handle image dimensions\n",
    "    if image.shape[0] == 1:  # Grayscale with singleton channel\n",
    "        image = image.squeeze(0)\n",
    "    elif image.shape[0] == 3:  # RGB with three channels\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "    if nuclei.shape[0] == 1:  # Grayscale nuclei image\n",
    "        nuclei = nuclei.squeeze(0)\n",
    "\n",
    "    # Extract nuclei centroids\n",
    "    regions = regionprops(nuclei)\n",
    "    centroids = [r.centroid for r in regions]\n",
    "\n",
    "    if not centroids:\n",
    "        print(\"[INFO] No nuclei centroids found in the provided nuclei image.\")\n",
    "        return\n",
    "\n",
    "    # Plot the H&E image with overlay\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(image, cmap=\"gray\" if image.ndim == 2 else None)  # Grayscale if 2D, otherwise RGB\n",
    "    plt.scatter(\n",
    "        [c[1] for c in centroids], [c[0] for c in centroids],\n",
    "        c=marker_color, s=marker_size, label=\"Nuclei Centroids\"\n",
    "    )\n",
    "    plt.title(f\"Overlay of Nuclei on {image_key}\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.legend()\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_nuclei_overlay(\n",
    "    sdata, image_key=\"HE_original\", nuclei_key=\"HE_nuc_original\",\n",
    "    marker_color=\"red\", marker_size=20\n",
    ")\n"
   ],
   "id": "444a61a82696a55d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 Nuclei Feature Distribution and Analysis\n",
    "In this step, we analyze key features of the nuclei such as their **area** and **eccentricity**. The analysis is visualized through histograms for easier interpretation.\n",
    "\n",
    "**Code Explanation:**\n",
    "- Compute the **area** and **eccentricity** of each nucleus using the `regionprops` method.\n",
    "- Display summary statistics, including the total number of nuclei, mean, and median values for both area and eccentricity.\n",
    "- Plot histograms to visualize the distributions of area and eccentricity.\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Area**: Represents the size of each nucleus.\n",
    "  - Mean Area: **46.24**\n",
    "  - Median Area: **44.00**\n",
    "- **Eccentricity**: Describes the elongation of the nucleus (value between 0 and 1, where 0 indicates a perfect circle).\n",
    "  - Mean Eccentricity: **0.68**\n",
    "  - Median Eccentricity: **0.71**\n",
    "\n",
    "**Results:**\n",
    "- The area distribution indicates most nuclei are between 30-70 units in size.\n",
    "- Eccentricity distribution shows a bias towards higher eccentricity, suggesting elongated nuclei are common in this dataset.\n",
    "\n",
    "---\n",
    "\n",
    "**Figures:**\n",
    "1. **Nuclei Area Distribution**:\n",
    "   - A histogram showing the frequency of nuclei sizes.\n",
    "   - Majority of nuclei fall within the 30-70 range, with a tail extending to larger sizes.\n",
    "\n",
    "2. **Nuclei Eccentricity Distribution**:\n",
    "   - A histogram displaying the frequency of eccentricity values.\n",
    "   - The distribution peaks around 0.6-0.8, showing a prevalence of moderately elongated nuclei."
   ],
   "id": "c09282ea3d5f3362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skimage.measure import regionprops, label\n",
    "\n",
    "def analyze_nuclei_features(nuclei_image):\n",
    "    \"\"\"\n",
    "    Analyze nuclei features such as area and eccentricity.\n",
    "\n",
    "    Args:\n",
    "        nuclei_image (np.ndarray): Binary nuclei image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Label nuclei regions\n",
    "    labeled_nuclei = label(nuclei_image)\n",
    "    regions = regionprops(labeled_nuclei)\n",
    "\n",
    "    areas = [r.area for r in regions]\n",
    "    eccentricities = [r.eccentricity for r in regions]\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\n[INFO] Nuclei Feature Analysis:\")\n",
    "    print(f\" - Total Nuclei: {len(regions)}\")\n",
    "    print(f\" - Mean Area: {np.mean(areas):.2f}\")\n",
    "    print(f\" - Median Area: {np.median(areas):.2f}\")\n",
    "    print(f\" - Mean Eccentricity: {np.mean(eccentricities):.2f}\")\n",
    "    print(f\" - Median Eccentricity: {np.median(eccentricities):.2f}\")\n",
    "\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(areas, bins=50, color=\"blue\", alpha=0.7)\n",
    "    plt.title(\"Nuclei Area Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Area\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(eccentricities, bins=50, color=\"green\", alpha=0.7)\n",
    "    plt.title(\"Nuclei Eccentricity Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Eccentricity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "nuclei_image = sdata.images[\"HE_nuc_original\"].to_numpy().squeeze(0)\n",
    "analyze_nuclei_features(nuclei_image)\n"
   ],
   "id": "33688e4a3dfa95f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **2.3 Generate a Nuclei Density Heatmap**\n",
    "\n",
    "A nuclei density heatmap provides insights into the spatial clustering and density of nuclei across the tissue section. This can be a valuable intermediate step for understanding tissue architecture.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.3.1 Nuclei Density Heatmap**\n",
    "This function will:\n",
    "1. Extract the centroids of nuclei from the binary nuclei image.\n",
    "2. Compute the density using kernel density estimation (KDE).\n",
    "3. Visualize the heatmap using `matplotlib`.\n"
   ],
   "id": "45fe7da9b0f69340"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def generate_nuclei_density_heatmap(nuclei_image, bins=100):\n",
    "    \"\"\"\n",
    "    Generate and display a nuclei density heatmap.\n",
    "\n",
    "    Args:\n",
    "        nuclei_image (np.ndarray): Binary nuclei image.\n",
    "        bins (int): Number of bins for the heatmap.\n",
    "    \"\"\"\n",
    "    # Extract nuclei centroids\n",
    "    labeled_nuclei = label(nuclei_image)\n",
    "    regions = regionprops(labeled_nuclei)\n",
    "    centroids = np.array([region.centroid for region in regions])\n",
    "\n",
    "    if centroids.size == 0:\n",
    "        print(\"[WARNING] No nuclei detected. Skipping heatmap generation.\")\n",
    "        return\n",
    "\n",
    "    # Perform kernel density estimation (KDE)\n",
    "    kde = gaussian_kde(centroids.T)\n",
    "    x = np.linspace(0, nuclei_image.shape[1], bins)\n",
    "    y = np.linspace(0, nuclei_image.shape[0], bins)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = kde(np.vstack([Y.ravel(), X.ravel()])).reshape(X.shape)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(Z, extent=(0, nuclei_image.shape[1], nuclei_image.shape[0], 0), cmap=\"hot\", alpha=0.7)\n",
    "    plt.colorbar(label=\"Nuclei Density\")\n",
    "    plt.title(\"Nuclei Density Heatmap\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "nuclei_image = sdata.images[\"HE_nuc_original\"].to_numpy().squeeze(0)\n",
    "generate_nuclei_density_heatmap(nuclei_image, bins=200)"
   ],
   "id": "380be52bc65d7b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skimage.measure import regionprops, label\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.colors import LogNorm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def enhanced_density_heatmap(nuclei_image, bins=200, contour_levels=10):\n",
    "    \"\"\"\n",
    "    Generate a high-resolution density heatmap with optimized KDE.\n",
    "\n",
    "    Args:\n",
    "        nuclei_image (np.ndarray): Binary nuclei image.\n",
    "        bins (int): Number of bins for the heatmap.\n",
    "        contour_levels (int): Number of contour levels.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract centroids\n",
    "    labeled_nuclei = label(nuclei_image)\n",
    "    regions = regionprops(labeled_nuclei)\n",
    "    centroids = np.array(\n",
    "        Parallel(n_jobs=-1)(\n",
    "            delayed(lambda r: r.centroid)(region) for region in regions\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if centroids.size == 0:\n",
    "        print(\"[WARNING] No nuclei detected. Skipping heatmap generation.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Perform KDE\n",
    "    kde = gaussian_kde(centroids.T)\n",
    "    x = np.linspace(0, nuclei_image.shape[1], bins)\n",
    "    y = np.linspace(0, nuclei_image.shape[0], bins)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = kde(np.vstack([Y.ravel(), X.ravel()])).reshape(X.shape)\n",
    "\n",
    "    # Step 3: Plot heatmap and contours\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(Z, extent=(0, nuclei_image.shape[1], nuclei_image.shape[0], 0),\n",
    "               cmap=\"hot\", norm=LogNorm(vmin=1e-2, vmax=Z.max()), alpha=0.8)\n",
    "    plt.colorbar(label=\"Nuclei Density\")\n",
    "\n",
    "    # Overlay contour lines\n",
    "    plt.contour(X, Y, Z, levels=contour_levels, colors=\"cyan\", alpha=0.7, linewidths=0.5)\n",
    "    plt.title(\"Enhanced Nuclei Density Heatmap\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "nuclei_image = sdata.images[\"HE_nuc_original\"].to_numpy().squeeze(0)\n",
    "enhanced_density_heatmap(nuclei_image, bins=200, contour_levels=15)\n"
   ],
   "id": "d51d8400f961e9e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3.2 DBSCAN and Density-Based Clustering\n",
    "\n",
    "#### 2.3.2.1 Basic DBSCAN with k-Distance Graph\n",
    "In this step, we implement a DBSCAN approach to cluster nuclei. We calculate an optimal epsilon (`eps`) using a k-distance graph and apply the DBSCAN algorithm to the extracted nuclei features.\n",
    "\n",
    "- **Steps**:\n",
    "  1. Extract basic nuclei features: centroid, area, and eccentricity.\n",
    "  2. Use a k-distance graph to determine the optimal epsilon (`eps`).\n",
    "  3. Apply DBSCAN clustering to the nuclei features.\n",
    "  4. Evaluate clustering quality using the following metrics:\n",
    "     - **Silhouette Score**: Measures how similar each point is to its own cluster compared to other clusters.\n",
    "     - **Davies-Bouldin Index**: Measures the ratio of within-cluster scatter to between-cluster separation.\n",
    "     - **Calinski-Harabasz Score**: Measures the variance ratio between clusters.\n",
    "\n",
    "- **Results**:\n",
    "  - k-Distance Graph: Visual inspection for the elbow point to determine the optimal epsilon value.\n",
    "  - Initial clustering evaluation metrics to benchmark performance.\n"
   ],
   "id": "87419a062dd4f077"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def calculate_optimal_eps(features: np.ndarray, k: int = 5):\n",
    "    \"\"\"\n",
    "    Calculate the optimal epsilon using k-distance graph for DBSCAN.\n",
    "\n",
    "    Args:\n",
    "        features (np.ndarray): Features for clustering.\n",
    "        k (int): Number of nearest neighbors.\n",
    "\n",
    "    Returns:\n",
    "        float: Suggested value of epsilon based on the elbow method.\n",
    "    \"\"\"\n",
    "    neighbors = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "    distances, _ = neighbors.fit(features).kneighbors(features)\n",
    "    k_distances = np.sort(distances[:, -1])  # Sort distances to k-th neighbor\n",
    "\n",
    "    # Plot k-distance graph for manual inspection\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_distances, marker='o', linestyle='--', markersize=3)\n",
    "    plt.title(\"k-Distance Graph for DBSCAN (Elbow Method)\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Points (sorted by distance)\")\n",
    "    plt.ylabel(f\"Distance to {k}-th Nearest Neighbor\")\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # Suggest epsilon at the elbow (90th percentile)\n",
    "    suggested_eps = np.percentile(k_distances, 90)\n",
    "    print(f\"[INFO] Suggested epsilon (eps): {suggested_eps:.4f}\")\n",
    "    return suggested_eps\n",
    "\n",
    "\n",
    "def dbscan_with_advanced_metrics(nuclei_image: np.ndarray, min_samples: int = 5, k: int = 5, use_pca: bool = True):\n",
    "    \"\"\"\n",
    "    Perform advanced DBSCAN clustering with full diagnostics and feature engineering.\n",
    "\n",
    "    Args:\n",
    "        nuclei_image (np.ndarray): Binary nuclei image.\n",
    "        min_samples (int): Minimum samples for DBSCAN.\n",
    "        k (int): Number of neighbors for epsilon estimation.\n",
    "        use_pca (bool): Whether to use PCA for dimensionality reduction.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with clustering results.\n",
    "        np.ndarray: Cluster labels.\n",
    "    \"\"\"\n",
    "    # Extract advanced nuclei features\n",
    "    labeled_nuclei = label(nuclei_image)\n",
    "    regions = regionprops(labeled_nuclei)\n",
    "    features = []\n",
    "\n",
    "    for region in regions:\n",
    "        compactness = (region.area) / (region.perimeter ** 2) if region.perimeter > 0 else 0\n",
    "        features.append([region.centroid[0], region.centroid[1], region.area, region.eccentricity, compactness])\n",
    "\n",
    "    features_df = pd.DataFrame(features, columns=[\"y\", \"x\", \"area\", \"eccentricity\", \"compactness\"])\n",
    "    print(\"[INFO] Extracted features for clustering:\")\n",
    "    display(features_df.head())\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features_df)\n",
    "\n",
    "    # Optional PCA\n",
    "    if use_pca:\n",
    "        pca = IncrementalPCA(n_components=2)\n",
    "        features_reduced = pca.fit_transform(features_scaled)\n",
    "        print(\"[INFO] Reduced features to 2 dimensions using PCA.\")\n",
    "    else:\n",
    "        features_reduced = features_scaled\n",
    "\n",
    "    # Compute optimal epsilon\n",
    "    eps = calculate_optimal_eps(features_reduced, k)\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "    cluster_labels = dbscan.fit_predict(features_reduced)\n",
    "    features_df[\"cluster\"] = cluster_labels\n",
    "\n",
    "    # Evaluate clustering performance\n",
    "    silhouette = silhouette_score(features_reduced, cluster_labels) if len(set(cluster_labels)) > 1 else -1\n",
    "    db_score = davies_bouldin_score(features_reduced, cluster_labels) if len(set(cluster_labels)) > 1 else -1\n",
    "    ch_score = calinski_harabasz_score(features_reduced, cluster_labels) if len(set(cluster_labels)) > 1 else -1\n",
    "\n",
    "    print(f\"[INFO] Silhouette Score: {silhouette:.4f}\")\n",
    "    print(f\"[INFO] Davies-Bouldin Index: {db_score:.4f} (lower is better)\")\n",
    "    print(f\"[INFO] Calinski-Harabasz Score: {ch_score:.4f} (higher is better)\")\n",
    "    return features_df, cluster_labels\n",
    "\n",
    "\n",
    "# Example usage\n",
    "dbscan_features_df, dbscan_labels = dbscan_with_advanced_metrics(nuclei_image, min_samples=10, k=10)\n"
   ],
   "id": "17431ab7def8ac9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.3.2.2 Advanced DBSCAN with Diagnostics and Feature Engineering\n",
    "Building upon the basic DBSCAN approach, we now introduce advanced diagnostics and feature engineering to improve clustering performance and interpretability.\n",
    "\n",
    "- **Enhancements**:\n",
    "  1. **Feature Engineering**:\n",
    "     - Add compactness as a feature to better characterize nuclei shapes.\n",
    "     - Optionally include intensity-based features (mean and standard deviation) for richer data representation.\n",
    "  2. **Dimensionality Reduction**:\n",
    "     - Use Incremental PCA to reduce feature dimensionality for large datasets, ensuring computational efficiency.\n",
    "  3. **Evaluation Metrics**:\n",
    "     - Evaluate clustering quality using silhouette score, Davies-Bouldin index, and Calinski-Harabasz score.\n",
    "  4. **Visualization**:\n",
    "     - Highlight outliers in clustering visualizations.\n",
    "     - Provide enhanced plots to interpret clusters in the spatial context.\n",
    "\n",
    "- **Results**:\n",
    "  - Optimized epsilon and `min_samples` values based on diagnostics.\n",
    "  - Improved clustering performance metrics.\n",
    "  - Visualizations showcasing well-defined clusters and detected outliers.\n",
    "\n",
    "- **Notes**:\n",
    "  - Further tuning of parameters (e.g., `eps`, `min_samples`) may lead to better results.\n",
    "  - Combining insights from density analysis (Step 2.3.1) can guide feature engineering and cluster interpretation.\n"
   ],
   "id": "f843114081b2f997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fbed35e5e3ce099a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
