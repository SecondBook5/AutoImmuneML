{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01_Preprocessing\n",
    "\n",
    "### Overview\n",
    "This notebook focuses on data preprocessing for Crunch 1 of the Autoimmune Disease Machine Learning Challenge. The preprocessing step is critical to prepare the raw spatial transcriptomics data and H&E images for downstream modeling tasks. It ensures data quality, consistency, and compatibility with machine learning algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives\n",
    "1. **Data Loading**: Load and validate raw data files (e.g., Zarr, H&E images, and gene expression tables).\n",
    "2. **Image Preprocessing**:\n",
    "   - Normalize H&E images.\n",
    "   - Extract nucleus-centered patches for modeling.\n",
    "3. **Gene Expression Preprocessing**:\n",
    "   - Normalize and filter gene expression data.\n",
    "   - Perform dimensionality reduction and clustering.\n",
    "4. **Spatial Feature Engineering**:\n",
    "   - Compute spatial features such as centroids, pairwise distances, and adjacency matrices.\n",
    "5. **Save Outputs**: Store preprocessed data in the `interim` directory for use in downstream tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Outputs\n",
    "- **Processed H&E Images**:\n",
    "  - Nucleus-centered patches with normalized intensities.\n",
    "- **Processed Gene Expression**:\n",
    "  - Normalized, filtered, and clustered gene expression data.\n",
    "- **Spatial Features**:\n",
    "  - Centroids, distances, and adjacency matrices for nuclei.\n",
    "\n",
    "---\n",
    "\n",
    "### Steps\n",
    "1. **Imports and Configuration**: Load necessary libraries and initialize configurations.\n",
    "2. **Data Loading**: Load raw data using the `DataLoader`.\n",
    "3. **Preprocessing Tasks**:\n",
    "   - Image Preprocessing (`ImagePreprocessor`).\n",
    "   - Gene Expression Preprocessing (`GenePreprocessor`).\n",
    "   - Spatial Preprocessing (`SpatialPreprocessor`).\n",
    "4. **Save Outputs**: Ensure all preprocessed data is saved to the `interim` directory.\n",
    "5. **Validation**: Validate preprocessed data visually or through summary statistics.\n"
   ],
   "id": "22460c92f6888e32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1. Imports and Configuration\n",
    "This section initializes the preprocessing environment by:\n",
    "- Importing core libraries and project-specific modules.\n",
    "- Loading the configuration file (`config.yaml`) for path management.\n",
    "- Setting up paths for raw and interim data."
   ],
   "id": "c693aef9c38b8597"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T07:07:43.546739Z",
     "start_time": "2025-01-14T07:07:38.954443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import spatialdata as sd\n",
    "import scanpy as sc"
   ],
   "id": "5d2c2fa709384905",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secondbook5/micromamba/envs/autoimmune_ml/lib/python3.11/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T07:08:10.725073Z",
     "start_time": "2025-01-14T07:08:10.566820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import project-specific modules\n",
    "from src.config.config_loader import ConfigLoader\n",
    "from src.data_loader import DataLoader\n",
    "from src.preprocessors.image_preprocessor import ImagePreprocessor\n",
    "from src.preprocessors.gene_preprocessor import GenePreprocessor\n",
    "from src.preprocessors.spatial_preprocessor import SpatialPreprocessor"
   ],
   "id": "147f82518a3fdf33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T07:08:12.518064Z",
     "start_time": "2025-01-14T07:08:12.510905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific warnings from zarr\n",
    "warnings.filterwarnings(\"ignore\", message=\"ignoring keyword argument 'read_only'\")\n"
   ],
   "id": "3ff1bf70bbd5b6d0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T07:08:14.400140Z",
     "start_time": "2025-01-14T07:08:14.371527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load configuration and DataLoader for Crunch1\n",
    "config_path = \"/home/secondbook5/projects/AutoImmuneML/config.yaml\"\n",
    "config = ConfigLoader(config_path=config_path)\n",
    "crunch_name = \"crunch1\"\n",
    "# initialize data loader\n",
    "data_loader = DataLoader(config=config, crunch_name=\"crunch1\")\n",
    "\n",
    "\n",
    "# Set paths\n",
    "raw_dir = config.get_crunch_path(crunch_name, \"raw_dir\")\n",
    "interim_dir = config.get_crunch_path(crunch_name, \"interim_dir\")\n",
    "\n",
    "# Display paths\n",
    "print(f\"Raw directory: {raw_dir}\")\n",
    "print(f\"Interim directory: {interim_dir}\")"
   ],
   "id": "994eda122ee98316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw directory: /mnt/d/AutoImmuneML/broad-1-autoimmune-crunch1/data\n",
      "Interim directory: /mnt/d/AutoImmuneML/broad-1-autoimmune-crunch1/interim\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Loading\n",
    "This section loads the raw data from Zarr files using the `DataLoader`. The data includes:\n",
    "1. **Images**: H&E registered images.\n",
    "2. **Tables**: Gene expression data.\n",
    "\n",
    "We also display a sample image and inspect the structure of the gene expression table to ensure correctness.\n"
   ],
   "id": "aa00dae9a902d079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T07:09:13.079887Z",
     "start_time": "2025-01-14T07:08:17.978675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validate specific Zarr files dynamically\n",
    "zarr_keys = [\"UC1_NI.zarr\", \"UC1_I.zarr\"]\n",
    "zarr_paths = [os.path.join(config.get_crunch_path(\"crunch1\", \"raw_dir\"), key) for key in zarr_keys]\n",
    "\n",
    "# Validate dynamically\n",
    "valid_zarr_paths = []\n",
    "for path in zarr_paths:\n",
    "    if os.path.isdir(path) and path.endswith(\".zarr\"):\n",
    "        valid_zarr_paths.append(path)\n",
    "    else:\n",
    "        print(f\"[WARNING] Invalid or missing Zarr path: {path}\")\n",
    "\n",
    "# Load valid Zarr datasets\n",
    "if valid_zarr_paths:\n",
    "    print(f\"[INFO] Loading Zarr datasets: {valid_zarr_paths}\")\n",
    "    zarr_data = data_loader.load_zarr(valid_zarr_paths)\n",
    "else:\n",
    "    print(\"[ERROR] No valid Zarr datasets to load.\")\n"
   ],
   "id": "81d45879bd819194",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Zarr datasets: ['/mnt/d/AutoImmuneML/broad-1-autoimmune-crunch1/data/UC1_NI.zarr', '/mnt/d/AutoImmuneML/broad-1-autoimmune-crunch1/data/UC1_I.zarr']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Zarr files: 100%|██████████| 2/2 [00:55<00:00, 27.51s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T07:24:10.208100Z",
     "start_time": "2025-01-14T07:21:28.982363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load all Zarr files in the raw directory\n",
    "print(f\"[INFO] Loading all Zarr files in directory: {raw_dir}\")\n",
    "all_zarr_data = data_loader.load_zarr([raw_dir])\n",
    "\n",
    "# Display loaded datasets\n",
    "print(f\"[INFO] All loaded datasets: {list(all_zarr_data.keys())}\")\n"
   ],
   "id": "fc8b2b6227a99c17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading all Zarr files in directory: /mnt/d/AutoImmuneML/broad-1-autoimmune-crunch1/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Zarr files: 100%|██████████| 8/8 [02:40<00:00, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All loaded datasets: ['DC1.zarr', 'UC1_NI.zarr', 'DC5.zarr', 'UC1_I.zarr', 'UC6_I.zarr', 'UC6_NI.zarr', 'UC7_I.zarr', 'UC9_I.zarr']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T05:32:28.952466Z",
     "start_time": "2025-01-14T05:25:37.354827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect loaded Zarr datasets\n",
    "print(\"[INFO] Inspecting loaded Zarr datasets...\")\n",
    "\n",
    "for key, dataset in zarr_data.items():\n",
    "    print(f\"[INFO] Dataset: {key}\")\n",
    "\n",
    "    # Check available images\n",
    "    if hasattr(dataset, \"images\") and dataset.images.keys():\n",
    "        print(f\"  - Images: {list(dataset.images.keys())}\")\n",
    "\n",
    "        # Display the first sample image for inspection\n",
    "        sample_image_key = list(dataset.images.keys())[0]\n",
    "        sample_image = dataset.images[sample_image_key].values\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.title(f\"{key} - Image: {sample_image_key}\")\n",
    "        plt.imshow(sample_image, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"  - No images found.\")\n",
    "\n",
    "    # Check available tables\n",
    "    if hasattr(dataset, \"tables\") and dataset.tables.keys():\n",
    "        print(f\"  - Tables: {list(dataset.tables.keys())}\")\n",
    "\n",
    "        # Display a preview of the first table\n",
    "        for table_key in dataset.tables.keys():\n",
    "            table = dataset.tables[table_key]\n",
    "            df = table.to_pandas()\n",
    "            print(f\"\\nSample rows from table '{table_key}':\")\n",
    "            print(df.head(5))\n",
    "    else:\n",
    "        print(\"  - No tables found.\")\n"
   ],
   "id": "47db008d8959750d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inspecting loaded Zarr datasets...\n",
      "[INFO] Dataset: UC1_NI.zarr\n",
      "  - Images: ['DAPI', 'DAPI_nuc', 'HE_nuc_original', 'HE_nuc_registered', 'HE_original', 'HE_registered', 'group', 'group_HEspace']\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T05:19:27.758420Z",
     "start_time": "2025-01-14T05:19:27.031263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display Sample Image and Metadata\n",
    "sample_image = zarr_data[\"UC1_NI\"][\"images\"][\"HE_registered\"]\n",
    "plt.imshow(sample_image)\n",
    "plt.title(\"Sample H&E Registered Image\")\n",
    "plt.show()\n",
    "\n",
    "# Display Sample Gene Expression Data\n",
    "gene_expression = pd.DataFrame(zarr_data[\"UC1_NI\"][\"tables\"][\"anucleus\"].to_numpy())\n",
    "print(gene_expression.head())"
   ],
   "id": "9c053e76c0277715",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UC1_NI'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Display Sample Image and Metadata\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m sample_image \u001B[38;5;241m=\u001B[39m \u001B[43mzarr_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mUC1_NI\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHE_registered\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(sample_image)\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSample H&E Registered Image\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'UC1_NI'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Preprocessing Tasks\n",
    "\n",
    "### 3.1 H&E Image Preprocessing\n",
    "- Normalize stains using Reinhard normalization.\n",
    "- Extract nucleus-centered patches.\n",
    "- Apply augmentations.\n"
   ],
   "id": "4563d13932537af7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Image Preprocessor\n",
    "image_preprocessor = ImagePreprocessor()\n",
    "\n",
    "# Normalize and Extract Patches\n",
    "for zarr_key, dataset in zarr_data.items():\n",
    "    he_images = dataset[\"images\"][\"HE_registered\"]\n",
    "    he_nuc_masks = dataset[\"images\"][\"HE_nuc_registered\"]\n",
    "\n",
    "    # Example: Normalize\n",
    "    normalized_images = image_preprocessor.normalize_stains(he_images)\n",
    "\n",
    "    # Example: Patch Extraction\n",
    "    patches = image_preprocessor.extract_patches(he_images, he_nuc_masks, patch_size=32)\n",
    "\n",
    "    # Save to Interim Directory\n",
    "    save_path = os.path.join(interim_dir, f\"{zarr_key}_processed_images.npy\")\n",
    "    np.save(save_path, patches)\n"
   ],
   "id": "8d0d0ab88f6cc821",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 Gene Expression Preprocessing\n",
    "- Normalize and filter gene expression data.\n",
    "- Log-transform if needed.\n"
   ],
   "id": "b4fe16d24dd3791e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Gene Preprocessor\n",
    "gene_preprocessor = GenePreprocessor()\n",
    "\n",
    "# Normalize Gene Expression\n",
    "for zarr_key, dataset in zarr_data.items():\n",
    "    anucleus_table = dataset[\"tables\"][\"anucleus\"]\n",
    "    normalized_genes = gene_preprocessor.normalize(anucleus_table)\n",
    "\n",
    "    # Save to Interim Directory\n",
    "    save_path = os.path.join(interim_dir, f\"{zarr_key}_processed_genes.npy\")\n",
    "    np.save(save_path, normalized_genes)\n"
   ],
   "id": "8d939bec198abb1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.3 Spatial Feature Engineering\n",
    "- Compute distances between nuclei.\n",
    "- Create adjacency matrices for spatial modeling.\n"
   ],
   "id": "daea59d2369d82b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Spatial Preprocessor\n",
    "spatial_preprocessor = SpatialPreprocessor()\n",
    "\n",
    "# Compute Features\n",
    "for zarr_key, dataset in zarr_data.items():\n",
    "    spatial_features = spatial_preprocessor.generate_features(dataset)\n",
    "\n",
    "    # Save to Interim Directory\n",
    "    save_path = os.path.join(interim_dir, f\"{zarr_key}_spatial_features.npy\")\n",
    "    np.save(save_path, spatial_features)\n"
   ],
   "id": "25967d8d944598db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Intermediate Validation\n",
    "- Visualize preprocessed images, gene distributions, and spatial features.\n"
   ],
   "id": "c266b49ca4c4eb86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize Preprocessed Images\n",
    "plt.imshow(patches[0])\n",
    "plt.title(\"Example Preprocessed Patch\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Gene Expression Distribution\n",
    "plt.hist(normalized_genes.flatten(), bins=50)\n",
    "plt.title(\"Normalized Gene Expression Distribution\")\n",
    "plt.show()\n"
   ],
   "id": "386f79c84b27bd32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Save Preprocessed Data\n",
    "- Save all outputs to the `interim` directory."
   ],
   "id": "7875dd2ad288e2ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure Preprocessed Data is Stored Correctly\n",
    "assert os.path.exists(interim_dir), \"Interim directory does not exist!\""
   ],
   "id": "3af2efee4404875a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Notes and Next Steps\n",
    "- Preprocessing is complete. The next step is Enhanced EDA.\n",
    "- Key Observations:\n",
    "  - ...\n",
    "  - ...\n"
   ],
   "id": "e7e8fdf358d59604"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
